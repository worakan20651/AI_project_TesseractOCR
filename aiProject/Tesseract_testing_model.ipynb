{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEyE1cCOdACa"
   },
   "source": [
    "## Optical Character Recognition (OCR)\n",
    "\n",
    "                            OCR\n",
    "                             |\n",
    "                      ------- ---------\n",
    "                      |               | \n",
    "                Online Text      Offline Text\n",
    "                                      |\n",
    "                               ------- ---------\n",
    "                               |               | \n",
    "                            Typed Text      Handwritten Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tra7zZvrnMZc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.7) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/seenam/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/seenam/.local/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import asrtoolkit\n",
    "from asrtoolkit import wer, cer\n",
    "import cv2\n",
    "import io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import sys\n",
    "import os\n",
    "from evaluate import load\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "cer = load(\"cer\")\n",
    "wer = load(\"wer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADB_d7xFfy5Z"
   },
   "source": [
    "## Files paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_part(filename):\n",
    "    # Extract the numerical part (e.g., 0001) from the filename\n",
    "    numeric_str = filename.split('-')[1].split('.')[0]\n",
    "    # Convert to an integer for sorting\n",
    "    return int(numeric_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg cer :  0.7902097902097902\n",
      "avg wer :  2.8\n",
      "avg rate :  0.4122534608248894\n"
     ]
    }
   ],
   "source": [
    "print(\"Test model 2 #training with handwritten font#\")\n",
    "\n",
    "# Directory containing the images\n",
    "image_folder = '../'\n",
    "predictions = []\n",
    "references = []\n",
    "# Directory containing your images\n",
    "sumCer = 0.0\n",
    "sumWer = 0.0\n",
    "Rate = 0.0\n",
    "count = 0.0\n",
    "# List all image files in the folder\n",
    "image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff')) and f.lower().startswith('pun')]\n",
    "\n",
    "# Loop through the image files and read each image\n",
    "for image_file in image_files:\n",
    "    # Read the image using OpenCV\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "    gt = image_path.split(\".png\")\n",
    "    gt_path = gt[0]+'.gt.txt'\n",
    "    with open(gt_path, 'r', encoding='utf-8') as file:\n",
    "        # Read the contents of the file\n",
    "        ground_truth = file.read()\n",
    "        # print(ground_truth)\n",
    "    references.append(ground_truth)\n",
    "\n",
    "    # Check if the image was successfully read\n",
    "    if image is not None:\n",
    "        # Process the image here, for example, display it\n",
    "        #pytesseract no preprocessing\n",
    "        hypothesis0 = pytesseract.image_to_string(image,lang='tha')\n",
    "        predictions.append(hypothesis0)\n",
    "        Rate += similar(ground_truth, hypothesis0)\n",
    "        count += 1\n",
    "    else:\n",
    "        print(f'Failed to read {image_file}')\n",
    "print(\"avg cer : \",cer.compute(predictions=predictions, references=references))\n",
    "print(\"avg wer : \",wer.compute(predictions=predictions, references=references))\n",
    "print(\"avg rate : \",Rate/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg cer :  2.2097902097902096\n",
      "avg wer :  1.4\n",
      "avg rate :  0.08625468336154787\n"
     ]
    }
   ],
   "source": [
    "print(\"Test model 1 #training with handwritten image#\")\n",
    "# Directory containing the images\n",
    "image_folder = '../'\n",
    "predictions = []\n",
    "references = []\n",
    "# Directory containing your images\n",
    "sumCer = 0.0\n",
    "sumWer = 0.0\n",
    "Rate = 0.0\n",
    "count = 0.0\n",
    "# List all image files in the folder\n",
    "image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff')) and f.lower().startswith('pun')]\n",
    "\n",
    "# Loop through the image files and read each image\n",
    "for image_file in image_files:\n",
    "    # Read the image using OpenCV\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "    gt = image_path.split(\".png\")\n",
    "    gt_path = gt[0]+'.gt.txt'\n",
    "    with open(gt_path, 'r', encoding='utf-8') as file:\n",
    "        # Read the contents of the file\n",
    "        ground_truth = file.read()\n",
    "        # print(ground_truth)\n",
    "    references.append(ground_truth)\n",
    "\n",
    "    # Check if the image was successfully read\n",
    "    if image is not None:\n",
    "        # Process the image here, for example, display it\n",
    "        #pytesseract no preprocessing\n",
    "        hypothesis0 = pytesseract.image_to_string(image,lang='tha1')\n",
    "        predictions.append(hypothesis0)\n",
    "        Rate += similar(ground_truth, hypothesis0)\n",
    "        count += 1\n",
    "    else:\n",
    "        print(f'Failed to read {image_file}')\n",
    "print(\"avg cer : \",cer.compute(predictions=predictions, references=references))\n",
    "print(\"avg wer : \",wer.compute(predictions=predictions, references=references))\n",
    "print(\"avg rate : \",Rate/count)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tesseract image preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
